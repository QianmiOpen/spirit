akka {
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  loglevel = DEBUG
//  loglevel = INFO

//  extensions = ["kamon.metric.Metrics", "kamon.statsd.StatsD"]

  actor {
    debug.receive = on

    provider = "akka.remote.RemoteActorRefProvider"

    deployment {
//      /SpiritCommands {
//        dispatcher = execute-dispatcher
//      }
      /SpiritHttpService {
        dispatcher = http-thread-pool-dispatcher
      }
    }
  }

  remote {
//    enabled-transports = ["akka.remote.netty.tcp"]
    netty.tcp {
//      hostname = "172.19.3.141"
      hostname = "192.168.59.3"
//      hostname = "127.0.0.1"
      port = "2552"
      send-buffer-size = 4m
      receive-buffer-size = 4m
      maximum-frame-size = 2m
    }
  }

}

spray.can.server {
  # uncomment the next line for making this an HTTPS example
  # ssl-encryption = on
  idle-timeout = 30 s
  request-timeout = 10 s

  request-chunk-aggregation-limit = 0

  port = 2551

  parsing.max-content-length = 10m
  parsing.incoming-auto-chunking-threshold-size = 5m
}

execute-dispatcher {
  # Dispatcher is the name of the event-based dispatcher
  type = Dispatcher
  # What kind of ExecutionService to use
  executor = "fork-join-executor"
  # Configuration for the fork join pool

  fork-join-executor {
    # Min number of threads to cap factor-based parallelism number to
    parallelism-min = 2
    # Parallelism (threads) ... ceil(available processors * factor)
    parallelism-factor = 2.0
    # Max number of threads to cap factor-based parallelism number to
    parallelism-max = 10
  }
  # Throughput defines the maximum number of messages to be
  # processed per actor before the thread jumps to the next actor.
  # Set to 1 for as fair as possible.
  throughput = 100
}


http-thread-pool-dispatcher {
  # Dispatcher is the name of the event-based dispatcher
  type = Dispatcher
  # What kind of ExecutionService to use
  executor = "thread-pool-executor"
  # Configuration for the thread pool
  thread-pool-executor {
    # minimum number of threads to cap factor-based core number to
    core-pool-size-min = 2
    # No of core threads ... ceil(available processors * factor)
    core-pool-size-factor = 2.0
    # maximum number of threads to cap factor-based number to
    core-pool-size-max = 10
  }
  # Throughput defines the maximum number of messages to be
  # processed per actor before the thread jumps to the next actor.
  # Set to 1 for as fair as possible.
  throughput = 100
}

//kamon {
//  statsd {
//    # Hostname and port in which your StatsD is running. Remember that StatsD packets are sent using UDP and
//    # setting unreachable hosts and/or not open ports wont be warned by the Kamon, your data wont go anywhere.
//    hostname = "172.19.5.250"
//    port = 8125
//
//    # Interval between metrics data flushes to StatsD. It's value must be equal or greater than the
//    # kamon.metrics.tick-interval setting.
//    flush-interval = 1 second
//
//    # Max packet size for UDP metrics data sent to StatsD.
//    max-packet-size = 1024 bytes
//
//    # Subscription patterns used to select which metrics will be pushed to StatsD. Note that first, metrics
//    # collection for your desired entities must be activated under the kamon.metrics.filters settings.
//    includes {
//      actor       = [ "*" ]
//      trace       = [ "*" ]
//      dispatcher  = [ "*" ]
//    }
//
//    simple-metric-key-generator {
//      # Application prefix for all metrics pushed to StatsD. The default namespacing scheme for metrics follows
//      # this pattern:
//      #    application.host.entity.entity-name.metric-name
//      application = "kamon"
//    }
//  }
//}

salt.master.keyPath="/etc/salt/pki/master/minions"